{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "import sys,os\n",
    "DPCOMP_PATH = '/nfs/avid/data1/miklau/dpcomp-parent/dpcomp_core_op'\n",
    "sys.path.append(DPCOMP_PATH)\n",
    "os.environ['DPCOMP_CORE']= DPCOMP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dpcomp_core.algorithm import *\n",
    "from dpcomp_core import dataset\n",
    "from dpcomp_core import util\n",
    "from dpcomp_core import workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of bins\n",
    "# domain = (256,)\n",
    "domain = 256\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "nickname = 'HEPTH'\n",
    "# nickname = 'BIDS-ALL'\n",
    "\n",
    "# number of data points from sample_to_scale data generation\n",
    "sample = 1e4\n",
    "\n",
    "# ESPairs = [(0.1, 1e4), (0.01, 1e5), (0.001, 1e6)]\n",
    "\n",
    "seed = 1\n",
    "\n",
    "seeds = range(5)\n",
    "\n",
    "# Instantiate dataset\n",
    "data = dataset.DatasetSampledFromFile(nickname=nickname, \n",
    "                                     sample_to_scale=sample, \n",
    "                                     reduce_to_dom_shape=domain, \n",
    "                                     seed=111)\n",
    "\n",
    "# Instantiate workload\n",
    "# w = workload.Identity(domain_shape=domain)\n",
    "w = workload.Prefix1D(domain_shape_int=domain)\n",
    "\n",
    "\n",
    "# Instantiate algorithms\n",
    "Identity_ = identity.identity_engine()\n",
    "HB_ = HB.HB_engine()\n",
    "MWEM_ = mwemND.mwemND_engine()\n",
    "DAWA_ = dawa.dawa_engine()\n",
    "\n",
    "algorithms = [(Identity_, \"Identity\"), (HB_, \"HB\"), (MWEM_, \"MWEM\"), (DAWA_, \"DAWA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 123, Index: 223\n"
     ]
    }
   ],
   "source": [
    "# original data\n",
    "dat = data.payload\n",
    "\n",
    "df = pd.DataFrame(dat)\n",
    "x = df.index.values\n",
    "y = df.values.flatten()\n",
    "\n",
    "clrs = ['red' if (k == max(y)) else 'black' for k in y ]\n",
    "orig = sns.barplot(x=x, y=y, palette=clrs)\n",
    "\n",
    "maxValOrig = max(y)\n",
    "maxValIndexOrig = y.argmax()\n",
    "\n",
    "print \"Max: %d, Index: %d\" % (maxVal, maxValIndex)\n",
    "\n",
    "orig.set_xticks([k for k in range(domain+20) if k % 20 == 0])\n",
    "orig.set_xticklabels([k for k in range(domain+20) if k % 20 == 0])\n",
    "# orig.set_ylim([0,12000])\n",
    "orig.set(xlabel='bins', ylabel='counts')\n",
    "orig.set_title('Original %s \\n Epsilon = %s, Domain = %s, Sample = %s' % (nickname, str(epsilon), str(domain), str(sample)))\n",
    "# sns.plt.show()\n",
    "# plt.gcf().clear()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datCDF= np.cumsum(dat)\n",
    "fig, cdf = plt.subplots()\n",
    "cdf.plot(datCDF)\n",
    "cdf.set_xticks([k for k in range(domain+20) if k % 20 == 0])\n",
    "cdf.set_xticklabels([k for k in range(domain+20) if k % 20 == 0])\n",
    "# cdf.set_ylim([0, 12000])\n",
    "cdf.set(xlabel='bins', ylabel='counts')\n",
    "cdf.set_title('Original %s (CDF) \\n Epsilon = %s, Domain = %s, Sample = %s' % (nickname, str(epsilon), str(domain), str(sample)))\n",
    "# sns.plt.show()\n",
    "# plt.gcf().clear()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Calculate and plot noisy estimates for x\n",
    "for seed in seeds:\n",
    "    print seed\n",
    "    for alg in algorithms:\n",
    "        x_hat = alg[0].Run(w, dat, epsilon, seed)\n",
    "        df_hat = pd.DataFrame(x_hat)\n",
    "        x_hat_data = df_hat.index.values\n",
    "        y_hat_data = df_hat.values.flatten()\n",
    "    #     print sum (y_hat_data)\n",
    "\n",
    "        # normalized non-negative rounding post-processing\n",
    "        negSum = sum(y_hat_data)\n",
    "        posSum = 0.00\n",
    "        for i in y_hat_data:\n",
    "            if i >= 0:\n",
    "                posSum += i\n",
    "        y_hat_data = [x*(negSum/posSum) if x >= 0 else 0 for x in y_hat_data]\n",
    "    #     print sum (y_hat_data)\n",
    "\n",
    "        maxVal = max(y_hat_data)\n",
    "        maxValIndex = y_hat_data.index(max(y_hat_data))\n",
    "        \n",
    "        # clone y_hat_data by slicing\n",
    "        y_hat_data_copy = y_hat_data[:]\n",
    "        y_hat_data_copy.remove(maxVal)\n",
    "        \n",
    "        second_maxVal = max(y_hat_data_copy)\n",
    "        second_maxValIndex = y_hat_data_copy.index(max(y_hat_data_copy))\n",
    "\n",
    "        clrs = ['red' if (k == maxVal) or (k == second_maxVal) else 'black' for k in y_hat_data ]\n",
    "        \n",
    "#         graph = sns.barplot(x=x_hat_data, y=y_hat_data, palette = clrs)\n",
    "#         graph.set_xticks([k for k in range(domain+20) if k % 20 == 0])\n",
    "#         graph.set_xticklabels([k for k in range(domain+20) if k % 20 == 0])\n",
    "#     #     graph.set_ylim([0,12000])\n",
    "#         graph.set(xlabel='bins', ylabel='counts')\n",
    "#         graph.set_title('%s %s \\n Epsilon = %s, Domain = %s, Sample = %s' % (alg[1], nickname, str(epsilon), str(domain), str(sample)))\n",
    "#         sns.plt.show()\n",
    "#         plt.gcf().clear()\n",
    "        plt.close()\n",
    "\n",
    "        datCDF_noisy = np.cumsum(y_hat_data)\n",
    "\n",
    "#         fig, cdf = plt.subplots()\n",
    "#         cdf.plot(datCDF)\n",
    "#         cdf.plot(datCDF_noisy)\n",
    "#         cdf.set_xticks([k for k in range(domain+20) if k % 20 == 0])\n",
    "#         cdf.set_xticklabels([k for k in range(domain+20) if k % 20 == 0])\n",
    "#     #     cdf.set_ylim([0, 1200000])\n",
    "#         cdf.set(xlabel='bins', ylabel='counts')\n",
    "#         cdf.set_title('%s %s (CDF) \\n Epsilon = %s, Domain = %s, Sample = %s' % (alg[1], nickname, str(epsilon), str(domain), str(sample)))\n",
    "#         sns.plt.show()\n",
    "#         plt.gcf().clear()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for alg in algorithms:\n",
    "    errors[alg[1]] = []\n",
    "    \n",
    "second_errors = {}\n",
    "for alg in algorithms:\n",
    "    second_errors[alg[1]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-379-bf55a84141c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         print \"Max: %d, Index: %d\" % (maxVal, maxValIndex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxValIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxValOrig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxValIndexOrig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0msecond_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_maxVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_maxValIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxValOrig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxValIndexOrig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "# Calculate and plot noisy estimates for x\n",
    "for seed in seeds:\n",
    "    print seed\n",
    "    for alg in algorithms:\n",
    "        x_hat = alg[0].Run(w, dat, epsilon, seed)\n",
    "        df_hat = pd.DataFrame(x_hat)\n",
    "        x_hat_data = df_hat.index.values\n",
    "        y_hat_data = df_hat.values.flatten()\n",
    "\n",
    "        # normalized non-negative rounding post-processing\n",
    "        negSum = sum(y_hat_data)\n",
    "        posSum = 0.00\n",
    "        for i in y_hat_data:\n",
    "            if i >= 0:\n",
    "                posSum += i\n",
    "        y_hat_data = [x*(negSum/posSum) if x >= 0 else 0 for x in y_hat_data]\n",
    "\n",
    "        maxVal = max(y_hat_data)\n",
    "        maxValIndex = y_hat_data.index(max(y_hat_data))\n",
    "        \n",
    "        # clone y_hat_data by slicing\n",
    "        y_hat_data_copy = y_hat_data[:]\n",
    "        y_hat_data_copy.remove(maxVal)\n",
    "        \n",
    "        second_maxVal = max(y_hat_data_copy)\n",
    "        second_maxValIndex = y_hat_data_copy.index(max(y_hat_data_copy))\n",
    "\n",
    "#         print \"Max: %d, Index: %d\" % (maxVal, maxValIndex)\n",
    "\n",
    "        errors[alg[1]].append(calculateError(maxVal, maxValIndex, maxValOrig, maxValIndexOrig))\n",
    "        second_errors[alg[1]].append(calculateError(second_maxVal, second_maxValIndex, maxValOrig, maxValIndexOrig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-457-2f6b99e85344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataCompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrigIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"M1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/nfs/avid/users4/dztam/errors.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, orig_data, noisy_data)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminNoisyIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoisy_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoisy_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrigIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxOrigIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "reload(errors)\n",
    "a = errors.DataCompare(y, y_hat_data)\n",
    "print a.maxOrig\n",
    "print a.maxOrigIndex\n",
    "print a.calcError(\"M1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-421-ba25619535af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msecond_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in errors:\n",
    "    print i, sum(errors[i])/len(errors[i])\n",
    "print \"\\n\"\n",
    "for i in second_errors:\n",
    "    print i, sum(second_errors[i])/len(second_errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
